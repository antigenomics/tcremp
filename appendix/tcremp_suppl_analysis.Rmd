---
title: "TCREMP supplementary"
author: "M.S."
output:
  pdf_document:
    latex_engine: xelatex
  html_document: default
date: "2025-01-09"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
Sys.setenv(VROOM_CONNECTION_SIZE = 2^25)
set.seed(42)
library(tidyverse)
library(reshape2)
library(stringr)
library(latex2exp)
library(ggplot2)
library(ggrastr) #install.packages("Cairo")
library(brms)
library(umap)
```

## Properties of TCREMP distances

First, lets show that TCREMP distances for CDR3$\beta$ region behave as expected. 
Given sequence similarities $s_{ij}$ one can obtain a metric $d_{ij} = s_{ii} + s_{jj} - 2 s_{ij}$
which can be also computed on-the-fly by transforming substitution scoring (e.g. BLOSUM matrix with gaps for linear gaps) appropriately.

We'll first analyze CDR3$\beta$ distances for $n=3000$ prototypes mapped to themselves 
and answer two questions:

* **Q1**: What is the distribution of alignment scores $d_{ij}$ and pairwise Euclidean distances $D_{ij}$ in embedding space
* **Q2**: The properties of Euclidean distances are well-known, but are the alignment scores additive (so PCA can be applied)? 
* **Q3**: How does pairwise distances in embedding space agree with actual alignment scores

Load data and compute alignment metric

```{r}
data.1 <- read_tsv("p1000_p1000.txt.gz") |>
  rename(from = id) |>
  mutate(from = as.character(from)) |>
  melt() |>
  filter(grepl("cdr3", variable)) |>
  mutate(to = str_split_fixed(variable, "_", 2)[,1]) |>
  select(-variable)

ids <- intersect(data.1$from, data.1$to)

data.1 <- data.1 |>
  filter(from %in% ids, to %in% ids)

data.1 <- data.1 |>
  rename(Sij = value) |>
  group_by(from) |>
  mutate(Sii = Sij[from == to]) |>
  group_by(to) |>
  mutate(Sjj = Sij[from == to]) |>
  ungroup() |>
  mutate(Dij = Sii + Sjj - 2 * Sij)

glimpse(data.1)
```

Compute embedding metric, append values

```{r}
data.1m <- data.1 |>
  dcast(from ~ to, value.var = "Dij")

rownames(data.1m) <- data.1m$from
data.1m$from <- NULL
data.1m <- as.matrix(data.1m)
data.1d <- dist(data.1m) |>
  as.matrix() |>
  melt()
colnames(data.1d) <- c("from", "to", "DDij")
data.1d$from <- as.character(data.1d$from)
data.1d$to <- as.character(data.1d$to)
data.1 <- left_join(data.1, data.1d)
glimpse(data.1)
```

We provide two fits for $d_{ij}$, first is $\mathcal{N}(\mu, \sigma)$ and the second 
one that recaptures the right-skewness is $\Gamma(\alpha = \mu^2 / \sigma^2, \lambda = \mu / \sigma^2)$,
the Gamma distribution.
This is in line with [Pang, H., Tang, J., Chen, SS. et al. Statistical distributions of optimal global alignment scores of random protein sequences. BMC Bioinformatics 6, 257 (2005)](https://doi.org/10.1186/1471-2105-6-257). A thorough theoretical proof for this is left for the reader.
We will just note that if, for first half of CDR3$\beta$ sequence $d_{ij}^{l} \sim \Gamma(\cdot)$ then 
$d_{ij} = d_{ij}^{l} + d_{ij}^r \sim \Gamma(\cdot)$ due to the nature of Gamma distribution. Also note that
number of matches between two random strings of amino acids can be modeled as a Poisson process which leads to Gamma distribution.

> N.B. We use Gamma distribution instead of Erlang distribution as sequence alignment scores may be non-integer

```{r fig.width=4, fig.height=3}
data.1diag <- data.1 |>
  filter(as.integer(from) < as.integer(to))

mu <- mean(data.1diag$Dij)
sigma <- sd(data.1diag$Dij)
alpha <- mu * mu / sigma / sigma
lambda <- alpha / mu

fig1 <- data.1diag |>
  ggplot(aes(x = Dij)) +
  geom_histogram(aes(y = after_stat(density)), 
                 binwidth = 50, 
                 color = "grey",
                 fill = "#b2abd2",
                 alpha = 0.7) +
  stat_function(fun = dnorm, 
                args = list(mean = mu, sd = sigma),
                color = "grey25") +
  stat_function(fun = dgamma, 
                args = list(shape = alpha, rate = lambda),  
                color = "#e66101") +
  xlab(TeX("$d_{ij}$")) + ylab(TeX("$P(d)$")) + 
  theme_classic() + 
  theme(axis.text.y = element_blank(), 
        axis.ticks.y = element_blank())
fig1
pdf("figs_aux_1A.pdf")
fig1
dev.off()
```

We can fit distribution of Euclidean distances $D_{ij}$ using a generalized 
extreme value (GEV) distribution $P_{GEV}(\mu, \sigma, \xi)$. It is said, that
GEV distribution is often used as an approximation to model the maxima of long 
(finite) sequences of random variables. Namely, we aim to  fit the Fréchet 
distribution aka type II GEV. We will first scale 
$D_{ij} \rightarrow \frac{D_{ij} - \text{E}[D_{ij}]}{\text{SD}[D_{ij}]}$ 
to simplify computations.

```{r}
DDij.mean <- mean(data.1diag$DDij)
DDij.sd <- sd(data.1diag$DDij)
ffit <- brm(formula = y ~ 1, 
            data = data.1diag |> 
              mutate(y = (DDij - DDij.mean) / DDij.sd), 
            family = "gen_extreme_value",
            cores = 10,
            seed = 42,
            iter = 500)
fvars <- summary(ffit)
print(fvars)
plot(ffit)
```

Plot results

```{r fig.width=4, fig.height=3}
fmu <- fvars$fixed$Estimate
fsigma <- fvars$spec_pars$Estimate[1]
fxi <- fvars$spec_pars$Estimate[2]

fig2 <- data.1diag |>
  ggplot(aes(x = DDij)) + 
  geom_histogram(aes(y = after_stat(density)), 
                 binwidth = 500, 
                 color = "grey",
                 fill = "#b2abd2",
                 alpha = 0.7) +
  geom_line(data = tibble(x = (-60:120 / 20) * DDij.sd + DDij.mean,
                          y = dgen_extreme_value(-60:120 / 20, 
                                       mu = fmu, 
                                       sigma = fsigma * 0.9,
                                       xi = fxi
                                     ) / DDij.sd
                          ),
                          aes(x, y), 
                color = "#e66101") +
  scale_x_continuous(TeX("$D_{ij}$")) +
  ylab(TeX("$P(D)$")) + 
  theme_classic() + 
  theme(axis.text.y = element_blank(), 
        axis.ticks.y = element_blank())
fig2
pdf("figs_aux_1B.pdf")
fig2
dev.off()
```


$\textbf{Q1}: d_{ij} \sim \Gamma, D_{ij} \sim \text{GEV}\,\,\square$

Check approx. additivity and triangle rule, circle through triplicates

```{r}
data.1tri <- expand_grid(a = 0:999, b = 0:999, c = 0:999) |>
  filter(a < b, b < c) |>
  mutate(a = as.character(a),
         b = as.character(b),
         c = as.character(c)) |>
  left_join(data.1 |>
              select(a = from, b = to, Dab = Dij, DDab = DDij) |>
              filter(a < b)) |>
  left_join(data.1 |>
              select(a = from, c = to, Dac = Dij, DDac = DDij) |>
              filter(a < c)) |>
  left_join(data.1 |>
              select(b = from, c = to, Dbc = Dij, DDbc = DDij) |>
              filter(b < c))
```

Plot them

```{r fig.width=4, fig.height=4}
fig3 <- data.1tri |>
  sample_n(100000) |>
  ggplot(aes(x = (Dab + Dbc) / 2, y = Dac)) +
  geom_hex(bins = 30) +
  scale_fill_distiller(palette = "Purples", direction = 1, guide = F) + 
  geom_abline(slope = 1, intercept = 0, 
              linetype = "dashed", color = "grey25") +
  scale_x_continuous(TeX("$(d_{ij} + d_{jk})/2$"), 
                     limits = c(100, 2000)) +
  scale_y_continuous(TeX("$d_{ik}$"), 
                     limits = c(100, 2000)) + 
  theme_classic() +
  theme(aspect.ratio = 1)

with(data.1tri,
     cor.test(Dab + Dbc, Dac))

fig3
pdf("figs_aux_2A.pdf")
fig3
dev.off()

fig4 <- data.1tri |>
  sample_n(100000) |>
  ggplot(aes(x = sqrt(DDab * DDbc), y = DDac)) +
  geom_hex(bins = 30) +
  scale_fill_distiller(palette = "Purples", direction = 1, guide = F) + 
  geom_abline(slope = 1, intercept = 0,
              linetype = "dashed", color = "grey25") +
  scale_x_continuous(TeX("$\\sqrt{D_{ij} \\times D_{jk}}$"), 
                     limits = c(1000, 20000)) +
  scale_y_continuous(TeX("$D_{ik}$"), limits = c(1000, 20000)) + 
  theme_classic() +
  theme(aspect.ratio = 1)

with(data.1tri,
     cor.test(sqrt(DDab * DDbc), DDac))

fig4
pdf("figs_aux_2B.pdf")
fig4
dev.off()
```

$\textbf{Q2}: d_{i,j} \sim d_{i,\cdot} + d_{\cdot,j}, \log D_{i,j} \sim \log D_{i,\cdot} + \log D_{\cdot,j}\,\,\square$

Compare alignment and embedding distances; also check that dissimilarity scores 
have good negative correlation with similarity scores

```{r fig.width=4, fig.height=4}
fig5 <- data.1diag |>
  ggplot(aes(x = Dij, y = Sij)) +
  geom_hex(bins = 30) +
  scale_fill_distiller(palette = "Purples", direction = 1, guide = F) + 
  geom_smooth(fill = NA, color = "#e66101") +
  scale_x_continuous(TeX("$d_{ij}$"), limits = c(0, 2000)) +
  scale_y_continuous(TeX("$s_{ij}$"), limits = c(0, 400)) + 
  theme_classic() +
  theme(aspect.ratio = 1)
with(data.1diag,
     cor.test(Dij, Sij))
with(data.1diag,
     cor.test(Sij, DDij))
fig5
pdf("figs_aux_2C.pdf")
fig5
dev.off()

fig6 <- data.1diag |>
  ggplot(aes(x = Dij, y = DDij)) +
  geom_hex(bins = 30) +
  scale_fill_distiller(palette = "Purples", direction = 1, guide = F) + 
  geom_smooth(fill = NA, color = "#e66101") +
  scale_x_continuous(TeX("$d_{ij}$"), limits = c(100, 2000)) +
  scale_y_continuous(TeX("$D_{ij}$"), limits = c(1000, 20000)) + 
  theme_classic() +
  theme(aspect.ratio = 1)
with(data.1diag,
     cor.test(Dij, DDij))
fig6
pdf("figs_aux_2D.pdf")
fig6
dev.off()
```

$\textbf{Q3}: D_{i,j} \sim d_{i,j} \,\,\square$

## Check difference between generated and real prototypes

Load similarity scores and compute Euclidean distances for prototypes obtained 
from VDJ rearrangement model ("Murugan") or real-world repertoires ("Britanova"). 
Note that here we use CDR3$\beta$ scores and omit V$\beta$, J$\beta$ as they are
quite predictable/discrete and are subject to batch effect/bias.

```{r}
read_proto <- function(prefix = "v_p", sz = 3000) {
  tmp <- read_tsv(paste0(prefix, sz, ".txt.gz")) |>
    select(cloneId, matches("b_\\d+_cdr3$")) |>
    melt(id.vars = "cloneId") |>
    dcast(cloneId ~ variable, mean)
  rownames(tmp) <- as.character(tmp$cloneId)
  tmp$cloneId <- NULL
  tmp |> 
    as.matrix() |>
    dist() |>
    as.matrix() |>
    melt() |>
    rename(from = Var1, to = Var2, Dp = value) 
}
v_p3000_d <- read_proto("v_p", 3000)
v_b3000_d <- read_proto("v_b", 3000) |> rename(Db = Dp)
v_bp3000_d <- merge(v_p3000_d, v_b3000_d)
```

Plot and correlate

```{r fig.width=4, fig.height=4}
fig7 <- v_bp3000_d |>
  ggplot(aes(x = Dp, y = Db)) +
  geom_hex(bins = 30) +
  scale_fill_distiller(palette = "Purples", direction = 1, guide = F) + 
  geom_smooth(method = "lm", fill = NA, color = "#e66101") +
  scale_x_continuous(TeX("$D_{ij}^{Murugan}$"), limits = c(1000, 20000)) + 
  scale_y_continuous(TeX("$D_{ij}^{Britanova}$"), limits = c(1000, 20000)) + 
  theme_classic() +
  theme(aspect.ratio = 1)
with(v_bp3000_d,
     cor.test(Dp, Db))
fig7
pdf("figs_aux_3.pdf")
fig7
dev.off()
```

$\textbf{Q4}: D_{ij}^{Model} \sim D_{ij}^{RepSeq}\,\,\square$

## Check effect fom the number of prototypes

Here we will again operate with CDR3$\beta$, look at the behavior of embeddings 
with $n_{proto} \in (100, 1000, 2000, 3000)$ prototypes.

```{r}
v_px <- bind_rows(
  read_proto("v_p", 100) |> mutate(n_prot = 100),
  read_proto("v_p", 1000) |> mutate(n_prot = 1000),
  read_proto("v_p", 2000) |> mutate(n_prot = 2000),
  read_proto("v_p", 3000) |> mutate(n_prot = 3000)
) |>
  left_join(read_tsv("v_p100.txt.gz") |>
              select(from = cloneId, ag = antigen.epitope) |>
              unique())
```

Do UMAP

```{r fig.width=6, fig.height=6}
do_umap <- function(data) {
  config <- umap.defaults
  config$n_neighbors <- config$n_neighbors * 3
  config$min_dist <- config$min_dist * 3
  emb <- data |>
    dcast(from ~ to, value.var = "Dp") |>
    umap(config = config)
  res <- emb$layout |>
    as.tibble()
  colnames(res) <- c("UMAP1", "UMAP2")
  cbind(data |> select(from, ag), res)
}

v_px_umap <- v_px |>
  group_by(n_prot) |>
  group_modify(~ do_umap(.x))

fig8 <- v_px_umap |>
  mutate(n_prot = paste0("p", n_prot)) |>
  group_by(n_prot) |>
  mutate(sgn_GIL_1 = sign(sum(UMAP1 * startsWith(ag, "GIL"))),
         sgn_GIL_2 = sign(sum(UMAP2 * startsWith(ag, "GIL")))) |>
  ungroup() |>
  ggplot(aes(x = UMAP1 * sgn_GIL_1, y = UMAP2 * sgn_GIL_2, fill = ag)) +
  geom_point_rast(shape = 21, 
                  color = "grey25", 
                  alpha = 0.7) +
  facet_wrap(~n_prot) +
  scale_color_brewer(palette = "PuOr") +
  xlab("UMAP1") + ylab("UMAP2") +
  theme_minimal() +
  theme(aspect.ratio = 1,
        legend.position = "bottom")
fig8
pdf("figs_aux_4.pdf")
fig8
dev.off()
```

$\textbf{Q5}: \text{UMAP stabilizes for}\,\,n_{proto} \geq 1000\,\,\square$

```{r}
print("Вот и сказочке конец")
```
